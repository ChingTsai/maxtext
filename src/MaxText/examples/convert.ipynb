{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f18ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/jimmy_workspace/maxtext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 07:01:29.006540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766732489.020303 3623831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766732489.024712 3623831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766732489.036111 3623831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766732489.036124 3623831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766732489.036126 3623831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766732489.036127 3623831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 07:01:32.978047: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jimmytsai_google_com/workspace/maxtext\n",
    "import MaxText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82720920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MaxText.utils.ckpt_conversion.to_maxtext import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7316159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='qwen2.5-14b'\n",
    "import dotenv\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "dotenv.load_dotenv(override=True)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "MAXTEXT_REPO_ROOT = os.path.dirname(MaxText.__file__)\n",
    "args = [\n",
    "    \"\",\n",
    "    f\"{MAXTEXT_REPO_ROOT}/configs/base.yml\",\n",
    "    f\"model_name={MODEL_NAME}\",\n",
    "    f\"hf_access_token={HF_TOKEN}\",\n",
    "    f'base_output_directory=\"/mnt/disks/jimmy_workspace/{MODEL_NAME}_checkpoint_v2/\"',\n",
    "    \"scan_layers=true\",\n",
    "    \"hardware=cpu\",\n",
    "    \"skip_jax_distributed_system=True\"\n",
    "]\n",
    "# Works exactly the same way\n",
    "test_args = SimpleNamespace(lazy_load_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25818a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping jax distributed system due to skip_jax_distributed_system=True flag.\n",
      " Setting num_slices=1 for CPU hardware type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MaxText.pyconfig:Config param act_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param activations_in_float32: False\n",
      "INFO:MaxText.pyconfig:Config param adam_b1: 0.9\n",
      "INFO:MaxText.pyconfig:Config param adam_b2: 0.95\n",
      "INFO:MaxText.pyconfig:Config param adam_eps: 1e-08\n",
      "INFO:MaxText.pyconfig:Config param adam_eps_root: 0.0\n",
      "INFO:MaxText.pyconfig:Config param adam_weight_decay: 0.1\n",
      "INFO:MaxText.pyconfig:Config param add_bos: True\n",
      "INFO:MaxText.pyconfig:Config param add_eos: True\n",
      "INFO:MaxText.pyconfig:Config param allow_split_physical_axes: False\n",
      "INFO:MaxText.pyconfig:Config param ar_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param async_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param attention: autoselected\n",
      "INFO:MaxText.pyconfig:Config param attention_bias: True\n",
      "INFO:MaxText.pyconfig:Config param attention_sink: False\n",
      "INFO:MaxText.pyconfig:Config param attention_type: global\n",
      "INFO:MaxText.pyconfig:Config param attn_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param autoregressive_decode_assert: \n",
      "INFO:MaxText.pyconfig:Config param base_emb_dim: 5120\n",
      "INFO:MaxText.pyconfig:Config param base_mlp_dim: 13824\n",
      "INFO:MaxText.pyconfig:Config param base_moe_mlp_dim: 7168\n",
      "INFO:MaxText.pyconfig:Config param base_num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param base_num_kv_heads: 8\n",
      "INFO:MaxText.pyconfig:Config param base_num_query_heads: 40\n",
      "INFO:MaxText.pyconfig:Config param base_output_directory: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_v2/\n",
      "INFO:MaxText.pyconfig:Config param batch_size: 1\n",
      "INFO:MaxText.pyconfig:Config param beta_fast: 32\n",
      "INFO:MaxText.pyconfig:Config param beta_slow: 1\n",
      "INFO:MaxText.pyconfig:Config param bwd_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param capacity_factor: -1.0\n",
      "INFO:MaxText.pyconfig:Config param cast_logits_to_fp32: True\n",
      "INFO:MaxText.pyconfig:Config param chat_template_path: \n",
      "INFO:MaxText.pyconfig:Config param checkpoint_conversion_fn: None\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_v2/qwen2.5-14b_2025-12-26-07-01/checkpoints/\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_is_quantized: False\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_period: 10000\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_concurrent_gb: 96\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_target_data_file_size_bytes: 2147483648\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_ocdbt: True\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_zarr3: True\n",
      "INFO:MaxText.pyconfig:Config param chips_per_vm: 4\n",
      "INFO:MaxText.pyconfig:Config param chunk_attn_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param collect_stack_trace: False\n",
      "INFO:MaxText.pyconfig:Config param colocated_python_data_input: False\n",
      "INFO:MaxText.pyconfig:Config param compile_topology: \n",
      "INFO:MaxText.pyconfig:Config param compile_topology_num_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param compiled_trainstep_file: \n",
      "INFO:MaxText.pyconfig:Config param compute_axis_order: 0,1,2,3\n",
      "INFO:MaxText.pyconfig:Config param constant_bound_config: []\n",
      "INFO:MaxText.pyconfig:Config param context: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_load_balance: True\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_size: 1\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_strategy: all_gather\n",
      "INFO:MaxText.pyconfig:Config param conv_stride_for_vit: 14\n",
      "INFO:MaxText.pyconfig:Config param cosine_learning_rate_final_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_bwd: -1\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_fwd: -1\n",
      "INFO:MaxText.pyconfig:Config param custom_mesh: \n",
      "INFO:MaxText.pyconfig:Config param data_sharding: (('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive'),)\n",
      "INFO:MaxText.pyconfig:Config param data_shuffle_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param dataset_path: \n",
      "INFO:MaxText.pyconfig:Config param dataset_type: DatasetType.TFDS\n",
      "INFO:MaxText.pyconfig:Config param dcn_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_data_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param dcn_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_parallelism: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param dcn_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param debug: {'rl': False}\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_nucleus_p: -1\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_strategy: SamplingStrategy.GREEDY\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_temperature: 1.0\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_top_k: 0\n",
      "INFO:MaxText.pyconfig:Config param decoder_block: DecoderBlockType.QWEN2\n",
      "INFO:MaxText.pyconfig:Config param decoder_layer_input: RematLocation.DEVICE\n",
      "INFO:MaxText.pyconfig:Config param deepstack_visual_indexes_for_vit: []\n",
      "INFO:MaxText.pyconfig:Config param dpo_beta: 0.1\n",
      "INFO:MaxText.pyconfig:Config param dpo_label_smoothing: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dq_reduction_steps: 0\n",
      "INFO:MaxText.pyconfig:Config param dropout_rate: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dtype: bfloat16\n",
      "INFO:MaxText.pyconfig:Config param dtype_mm: float32\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_delete_local_after: True\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_gcs_dir: \n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_dir: /tmp/xla_dump/\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_upload_all: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_xla_flags: \n",
      "INFO:MaxText.pyconfig:Config param dump_step: -1\n",
      "INFO:MaxText.pyconfig:Config param emb_dim: 5120\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpoint_cloud_logger: False\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param enable_data_shuffling: True\n",
      "INFO:MaxText.pyconfig:Config param enable_dropout: True\n",
      "INFO:MaxText.pyconfig:Config param enable_emergency_checkpoint: False\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_goodput_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_step_deviation_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_goodput_recording: False\n",
      "INFO:MaxText.pyconfig:Config param enable_jax_profiler: False\n",
      "INFO:MaxText.pyconfig:Config param enable_llm_inference_pool: False\n",
      "INFO:MaxText.pyconfig:Config param enable_model_warmup: False\n",
      "INFO:MaxText.pyconfig:Config param enable_multi_tier_checkpointing: False\n",
      "INFO:MaxText.pyconfig:Config param enable_nnx: False\n",
      "INFO:MaxText.pyconfig:Config param enable_orbax_v1: False\n",
      "INFO:MaxText.pyconfig:Config param enable_padding_causal_mask: True\n",
      "INFO:MaxText.pyconfig:Config param enable_pathways_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param enable_prefix_caching: False\n",
      "INFO:MaxText.pyconfig:Config param enable_rampup_batch_size: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_controller: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_replica_ckpt_restoring: False\n",
      "INFO:MaxText.pyconfig:Config param enable_tensorboard: True\n",
      "INFO:MaxText.pyconfig:Config param enable_tunix_perf_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param eval_corr_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param eval_dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param eval_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param eval_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param eval_make_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_per_device_batch_size: 12.0\n",
      "INFO:MaxText.pyconfig:Config param eval_sampling_strategy: greedy\n",
      "INFO:MaxText.pyconfig:Config param eval_split: validation\n",
      "INFO:MaxText.pyconfig:Config param eval_steps: -1\n",
      "INFO:MaxText.pyconfig:Config param expansion_factor_real_data: -1.0\n",
      "INFO:MaxText.pyconfig:Config param expert_shard_attention_option: fsdp\n",
      "INFO:MaxText.pyconfig:Config param final_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param first_num_dense_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param float32_logits: False\n",
      "INFO:MaxText.pyconfig:Config param float32_qk_product: False\n",
      "INFO:MaxText.pyconfig:Config param float32_weight_sum: True\n",
      "INFO:MaxText.pyconfig:Config param force_unroll: False\n",
      "INFO:MaxText.pyconfig:Config param freeze_vision_encoder_params: True\n",
      "INFO:MaxText.pyconfig:Config param fsdp_shard_on_exp: False\n",
      "INFO:MaxText.pyconfig:Config param fused_mlp: False\n",
      "INFO:MaxText.pyconfig:Config param fused_qkv: False\n",
      "INFO:MaxText.pyconfig:Config param gcs_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param gdn_chunk_size: 64\n",
      "INFO:MaxText.pyconfig:Config param gdn_conv_kernel_dim: 4\n",
      "INFO:MaxText.pyconfig:Config param gdn_key_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_key_heads: 16\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_value_heads: 32\n",
      "INFO:MaxText.pyconfig:Config param gdn_value_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_eval: False\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_train: False\n",
      "INFO:MaxText.pyconfig:Config param generate_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param generation_configs: {}\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_eval_on: 12\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load: 12\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_eval: 12\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_increment: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_start: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_train_on: 12\n",
      "INFO:MaxText.pyconfig:Config param global_parameter_scale: 1\n",
      "INFO:MaxText.pyconfig:Config param global_rampup_samples: 500\n",
      "INFO:MaxText.pyconfig:Config param goodput_upload_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param grad_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param gradient_accumulation_steps: 1\n",
      "INFO:MaxText.pyconfig:Config param gradient_clipping_threshold: 1.0\n",
      "INFO:MaxText.pyconfig:Config param grain_data_source_max_workers: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_eval_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_file_type: arrayrecord\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads_eval: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size_eval: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_train_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param grpo_beta: 0.08\n",
      "INFO:MaxText.pyconfig:Config param grpo_epsilon: 0.2\n",
      "INFO:MaxText.pyconfig:Config param hardware: cpu\n",
      "INFO:MaxText.pyconfig:Config param hbm_utilization_vllm: 0.72\n",
      "INFO:MaxText.pyconfig:Config param head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param heartbeat_reporting_interval_in_seconds: 5\n",
      "INFO:MaxText.pyconfig:Config param hf_data_dir: \n",
      "INFO:MaxText.pyconfig:Config param hf_eval_files: None\n",
      "INFO:MaxText.pyconfig:Config param hf_eval_split: \n",
      "INFO:MaxText.pyconfig:Config param hf_path: \n",
      "INFO:MaxText.pyconfig:Config param hf_train_files: None\n",
      "INFO:MaxText.pyconfig:Config param hidden_size_for_vit: 1408\n",
      "INFO:MaxText.pyconfig:Config param hide_profiler_step_metric: False\n",
      "INFO:MaxText.pyconfig:Config param ici_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_data_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_parallelism: [1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param ici_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param image_path: \n",
      "INFO:MaxText.pyconfig:Config param image_placeholder: <|image|>\n",
      "INFO:MaxText.pyconfig:Config param image_size_for_vit: 896\n",
      "INFO:MaxText.pyconfig:Config param inference_benchmark_test: False\n",
      "INFO:MaxText.pyconfig:Config param inference_metadata_file: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_log_file_path: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_loop_iters: 10\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_num_samples: [1, 2, 3, 4, 5]\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_prefill_lengths: 64,128,256,512,1024\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_stages: prefill,generate\n",
      "INFO:MaxText.pyconfig:Config param inference_server: MaxtextInterleavedServer\n",
      "INFO:MaxText.pyconfig:Config param inhomogeneous_layer_cycle_interval: 1\n",
      "INFO:MaxText.pyconfig:Config param init_weights_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param input_data_sharding_logical_axes: ['activation_embed_and_logits_batch', 'activation_norm_length']\n",
      "INFO:MaxText.pyconfig:Config param interleave_moe_layer_step: 1\n",
      "INFO:MaxText.pyconfig:Config param intermediate_size_for_vit: 5632\n",
      "INFO:MaxText.pyconfig:Config param jax_cache_dir: ~/jax_cache\n",
      "INFO:MaxText.pyconfig:Config param jax_debug_log_modules: \n",
      "INFO:MaxText.pyconfig:Config param jax_distributed_initialization_timeout: 300\n",
      "INFO:MaxText.pyconfig:Config param jax_profiler_port: 9999\n",
      "INFO:MaxText.pyconfig:Config param key_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param kv_cache_buffer: 256\n",
      "INFO:MaxText.pyconfig:Config param kv_lora_rank: 512\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_axis: KvQuantAxis.HEADS_AND_DKV\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_dtype: int8\n",
      "INFO:MaxText.pyconfig:Config param learning_rate: 3e-05\n",
      "INFO:MaxText.pyconfig:Config param learning_rate_schedule_steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param load_balance_loss_weight: 0.01\n",
      "INFO:MaxText.pyconfig:Config param load_from_prefill_dir: False\n",
      "INFO:MaxText.pyconfig:Config param load_full_state_path: \n",
      "INFO:MaxText.pyconfig:Config param load_parameters_path: \n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_directory: \n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_period: 0\n",
      "INFO:MaxText.pyconfig:Config param local_rope_max_timescale: -1\n",
      "INFO:MaxText.pyconfig:Config param log_config: True\n",
      "INFO:MaxText.pyconfig:Config param log_period: 100\n",
      "INFO:MaxText.pyconfig:Config param logical_axis_rules: (('activation_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_embed_and_logits_batch', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_embed_and_logits_batch_sequence', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('activation_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence', 'autoregressive')), ('activation_kv_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_length', ('sequence', 'context', 'expert')), ('activation_length', ('context', 'expert')), ('activation_length_no_exp', ('sequence', 'context')), ('activation_length_no_exp', ('context',)), ('activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_q_length', ('context', 'expert')), ('activation_q_length_no_exp', ('context',)), ('prefill_activation_length', ('sequence', 'context')), ('prefill_activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_kv_length', ()), ('activation_embed', ('tensor', 'tensor_transpose')), ('activation_mlp', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_kv', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_prefill_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_kv_head_dim', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose')), ('activation_vocab', 'tensor_sequence'), ('activation_vocab', ('sequence', 'context')), ('activation_stage', 'stage'), ('activation_exp', ('expert',)), ('decode_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('decode_length', ('sequence',)), ('mlp', ('fsdp_transpose', 'tensor', 'tensor_sequence', 'autoregressive')), ('mlp_no_fsdp', ('tensor', 'tensor_sequence', 'autoregressive')), ('vocab', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('q_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('kv_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'context', 'expert')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'context')), ('embed_tensor_transpose', ('tensor_transpose',)), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'expert')), ('q_lora_up_proj', ()), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'expert')), ('kv_lora_up_proj', ()), ('norm', ('tensor', 'tensor_transpose')), ('layers', 'stage'), ('kv', ()), ('kv_head_dim', ()), ('cache_batch_prefill', ()), ('cache_batch', ()), ('cache_heads_none', ()), ('cache_heads', ('autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence')), ('cache_heads', ('autoregressive', 'tensor', 'tensor_sequence')), ('cache_kv', ()), ('cache_sequence', ()), ('exp', 'expert'), ('paged_kv_heads', ('tensor',)), ('num_pages', ()), ('tokens_per_page', ()), ('paged_kv_head_dim_size', ()), ('dense_layers', ()), ('moe_layers', ()))\n",
      "INFO:MaxText.pyconfig:Config param logits_dot_in_fp32: False\n",
      "INFO:MaxText.pyconfig:Config param logits_via_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param lora_input_adapters_path: \n",
      "INFO:MaxText.pyconfig:Config param loss_algo: grpo\n",
      "INFO:MaxText.pyconfig:Config param matmul_precision: MatmulPrecision.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param max_checkify: False\n",
      "INFO:MaxText.pyconfig:Config param max_corpus_chars: 10000000\n",
      "INFO:MaxText.pyconfig:Config param max_num_checkpoints_to_keep: None\n",
      "INFO:MaxText.pyconfig:Config param max_num_images_per_example: -1\n",
      "INFO:MaxText.pyconfig:Config param max_position_embeddings: 163840\n",
      "INFO:MaxText.pyconfig:Config param max_prefill_predict_length: 64\n",
      "INFO:MaxText.pyconfig:Config param max_segments_per_seq: 32\n",
      "INFO:MaxText.pyconfig:Config param max_target_length: 2048\n",
      "INFO:MaxText.pyconfig:Config param megablox: True\n",
      "INFO:MaxText.pyconfig:Config param mesh_axes: ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive']\n",
      "INFO:MaxText.pyconfig:Config param metrics_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_v2/qwen2.5-14b_2025-12-26-07-01/metrics/\n",
      "INFO:MaxText.pyconfig:Config param metrics_file: \n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size: -1\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_eval_on: 12\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_train_on: 12\n",
      "INFO:MaxText.pyconfig:Config param mla_naive_kvcache: True\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations: ['silu', 'linear']\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations_limit: -1.0\n",
      "INFO:MaxText.pyconfig:Config param mlp_bias: False\n",
      "INFO:MaxText.pyconfig:Config param mlp_dim: 13824\n",
      "INFO:MaxText.pyconfig:Config param mlpwi: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_0: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_1: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwo: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param moba: False\n",
      "INFO:MaxText.pyconfig:Config param moba_chunk_size: 1024\n",
      "INFO:MaxText.pyconfig:Config param moba_topk: 8\n",
      "INFO:MaxText.pyconfig:Config param model_call_mode: \n",
      "INFO:MaxText.pyconfig:Config param model_fsdp_ag_once: False\n",
      "INFO:MaxText.pyconfig:Config param model_name: qwen2.5-14b\n",
      "INFO:MaxText.pyconfig:Config param moe_fsdp_use_two_stage_all_gather: False\n",
      "INFO:MaxText.pyconfig:Config param moe_mlp_dim: 7168\n",
      "INFO:MaxText.pyconfig:Config param monitor_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param monitor_step_time_deviation: True\n",
      "INFO:MaxText.pyconfig:Config param mscale: 1.0\n",
      "INFO:MaxText.pyconfig:Config param mtc_data_parallelism: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_eval_target_module: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_loss_scaling_factor: 0.1\n",
      "INFO:MaxText.pyconfig:Config param mtp_num_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param mu_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param multi_sampling: False\n",
      "INFO:MaxText.pyconfig:Config param multi_tier_checkpointing_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param n_routing_groups: -1\n",
      "INFO:MaxText.pyconfig:Config param nope_layer_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param norm_topk_prob: False\n",
      "INFO:MaxText.pyconfig:Config param normalization_layer_epsilon: 1e-06\n",
      "INFO:MaxText.pyconfig:Config param normalize_embedding_logits: False\n",
      "INFO:MaxText.pyconfig:Config param num_attention_heads_for_vit: 16\n",
      "INFO:MaxText.pyconfig:Config param num_batches: 4\n",
      "INFO:MaxText.pyconfig:Config param num_channels_for_vit: 3\n",
      "INFO:MaxText.pyconfig:Config param num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param num_epoch: 1\n",
      "INFO:MaxText.pyconfig:Config param num_eval_passes: 1\n",
      "INFO:MaxText.pyconfig:Config param num_experts: 1\n",
      "INFO:MaxText.pyconfig:Config param num_experts_per_tok: 1\n",
      "INFO:MaxText.pyconfig:Config param num_generations: 2\n",
      "INFO:MaxText.pyconfig:Config param num_hidden_layers_for_vit: 34\n",
      "INFO:MaxText.pyconfig:Config param num_iterations: 1\n",
      "INFO:MaxText.pyconfig:Config param num_kv_heads: 8\n",
      "INFO:MaxText.pyconfig:Config param num_layers_per_pipeline_stage: 1\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_microbatches: -1\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_repeats: -1\n",
      "INFO:MaxText.pyconfig:Config param num_position_embeddings_for_vit: 1024\n",
      "INFO:MaxText.pyconfig:Config param num_query_heads: 40\n",
      "INFO:MaxText.pyconfig:Config param num_samplers_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_slices: 1\n",
      "INFO:MaxText.pyconfig:Config param num_test_batches: 5\n",
      "INFO:MaxText.pyconfig:Config param num_trainer_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_vocab_tiling: 1\n",
      "INFO:MaxText.pyconfig:Config param opt_type: OptimizerType.ADAMW\n",
      "INFO:MaxText.pyconfig:Config param optimize_mesh_for_tpu_v6e: False\n",
      "INFO:MaxText.pyconfig:Config param optimizer_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param original_max_position_embeddings: 4096\n",
      "INFO:MaxText.pyconfig:Config param out_hidden_size_for_vit: 512\n",
      "INFO:MaxText.pyconfig:Config param out_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param override_model_config: False\n",
      "INFO:MaxText.pyconfig:Config param packing: True\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_head_dim_alignment: 128\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_max_pages_per_group: -1\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_num_pages: 64\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_pages_per_compute_block: 4\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_tokens_per_page: 32\n",
      "INFO:MaxText.pyconfig:Config param param_scan_axis: 1\n",
      "INFO:MaxText.pyconfig:Config param parameter_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param partial_rotary_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param patch_size_for_vit: 14\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_answer: -1.0\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_format: -0.5\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size: 12.0\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_increment: 2.0\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_start: 4.0\n",
      "INFO:MaxText.pyconfig:Config param pipeline_delay_activation_forwarding: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_fsdp_ag_once: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_parallel_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param pixel_shuffle_ratio_for_vit: 0.5\n",
      "INFO:MaxText.pyconfig:Config param posemb_type_for_vit: learn\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_dir: \n",
      "INFO:MaxText.pyconfig:Config param prefill_chunk_size: 256\n",
      "INFO:MaxText.pyconfig:Config param prefill_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_dram_byte: 100000000000\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_hbm_byte: 10000000000\n",
      "INFO:MaxText.pyconfig:Config param profile_cleanly: True\n",
      "INFO:MaxText.pyconfig:Config param profile_periodically_period: -1\n",
      "INFO:MaxText.pyconfig:Config param profiler: ProfilerType.NONE\n",
      "INFO:MaxText.pyconfig:Config param profiler_steps: 5\n",
      "INFO:MaxText.pyconfig:Config param projector_dropout_for_vit: 0.0\n",
      "INFO:MaxText.pyconfig:Config param projector_input_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param projector_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param prometheus_port: 0\n",
      "INFO:MaxText.pyconfig:Config param prompt: I love to\n",
      "INFO:MaxText.pyconfig:Config param q_lora_rank: 0\n",
      "INFO:MaxText.pyconfig:Config param qk_nope_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param qk_rope_head_dim: 64\n",
      "INFO:MaxText.pyconfig:Config param qkv_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param quant_cfg_path: \n",
      "INFO:MaxText.pyconfig:Config param quantization: QuantizationType.NONE\n",
      "INFO:MaxText.pyconfig:Config param quantization_local_shard_count: 1\n",
      "INFO:MaxText.pyconfig:Config param quantize_kvcache: False\n",
      "INFO:MaxText.pyconfig:Config param query_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param ragged_block_size: 256\n",
      "INFO:MaxText.pyconfig:Config param rampup_end_step: 0\n",
      "INFO:MaxText.pyconfig:Config param rampup_samples_per_increment_to_load: None\n",
      "INFO:MaxText.pyconfig:Config param reasoning_end_token: </reasoning>\n",
      "INFO:MaxText.pyconfig:Config param reasoning_start_token: <reasoning>\n",
      "INFO:MaxText.pyconfig:Config param record_internal_nn_metrics: 0\n",
      "INFO:MaxText.pyconfig:Config param remat_policy: full\n",
      "INFO:MaxText.pyconfig:Config param remat_policy_for_vit: minimal\n",
      "INFO:MaxText.pyconfig:Config param replicate_quant_scale: False\n",
      "INFO:MaxText.pyconfig:Config param replicator_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param report_heartbeat_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param report_performance_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param reshape_q: False\n",
      "INFO:MaxText.pyconfig:Config param return_log_prob: False\n",
      "INFO:MaxText.pyconfig:Config param reuse_example_batch: 0\n",
      "INFO:MaxText.pyconfig:Config param reward_exact_format_match: 3.0\n",
      "INFO:MaxText.pyconfig:Config param reward_partial_format_match: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_high: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_low: 0.25\n",
      "INFO:MaxText.pyconfig:Config param reward_white_space_format_match: 1.5\n",
      "INFO:MaxText.pyconfig:Config param rope_attention_scaling: False\n",
      "INFO:MaxText.pyconfig:Config param rope_factor: 40\n",
      "INFO:MaxText.pyconfig:Config param rope_interleave: True\n",
      "INFO:MaxText.pyconfig:Config param rope_linear_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param rope_max_timescale: 1000000\n",
      "INFO:MaxText.pyconfig:Config param rope_min_timescale: 1\n",
      "INFO:MaxText.pyconfig:Config param rope_theta_for_vit: 10000\n",
      "INFO:MaxText.pyconfig:Config param rope_truncate: True\n",
      "INFO:MaxText.pyconfig:Config param rope_type: RopeType.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param rope_use_scale: True\n",
      "INFO:MaxText.pyconfig:Config param routed_bias: False\n",
      "INFO:MaxText.pyconfig:Config param routed_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param routed_score_func: \n",
      "INFO:MaxText.pyconfig:Config param run_name: qwen2.5-14b_2025-12-26-07-01\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_k_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_q_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_use_fused_bwd_kernel: False\n",
      "INFO:MaxText.pyconfig:Config param sa_v_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sampler_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param save_checkpoint_on_completion: True\n",
      "INFO:MaxText.pyconfig:Config param save_config_to_gcs: False\n",
      "INFO:MaxText.pyconfig:Config param save_quantized_params_path: \n",
      "INFO:MaxText.pyconfig:Config param scan_layers: True\n",
      "INFO:MaxText.pyconfig:Config param scan_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param scan_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param sft_train_on_completion_only: False\n",
      "INFO:MaxText.pyconfig:Config param shard_mode: ShardMode.AUTO\n",
      "INFO:MaxText.pyconfig:Config param shard_optimizer_over_data: False\n",
      "INFO:MaxText.pyconfig:Config param sharding_strategy: None\n",
      "INFO:MaxText.pyconfig:Config param sharding_tolerance: 0.02\n",
      "INFO:MaxText.pyconfig:Config param shardy: True\n",
      "INFO:MaxText.pyconfig:Config param shared_experts: 1\n",
      "INFO:MaxText.pyconfig:Config param skip_first_n_steps_for_profiler: 1\n",
      "INFO:MaxText.pyconfig:Config param skip_jax_distributed_system: True\n",
      "INFO:MaxText.pyconfig:Config param sliding_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param solution_end_token: </answer>\n",
      "INFO:MaxText.pyconfig:Config param solution_start_token: <answer>\n",
      "INFO:MaxText.pyconfig:Config param source_checkpoint_layout: orbax\n",
      "INFO:MaxText.pyconfig:Config param sparse_matmul: True\n",
      "INFO:MaxText.pyconfig:Config param spatial_merge_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param stack_prefill_result_cache: False\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_interval_seconds: 600\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_to_cloud: False\n",
      "INFO:MaxText.pyconfig:Config param step_deviation_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param subslice_shape: \n",
      "INFO:MaxText.pyconfig:Config param swap_space_vllm_gb: 2\n",
      "INFO:MaxText.pyconfig:Config param target_eval_loss: 0.0\n",
      "INFO:MaxText.pyconfig:Config param temperature_tuning: False\n",
      "INFO:MaxText.pyconfig:Config param temporal_patch_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param tensorboard_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_v2/qwen2.5-14b_2025-12-26-07-01/tensorboard/\n",
      "INFO:MaxText.pyconfig:Config param tensors_on_device: None\n",
      "INFO:MaxText.pyconfig:Config param tensors_to_offload: None\n",
      "INFO:MaxText.pyconfig:Config param tile_size_for_vit: 336\n",
      "INFO:MaxText.pyconfig:Config param tokenize_eval_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenize_train_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_path: src/MaxText/assets/tokenizer.llama2\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_type: TokenizerType.HUGGINGFACE\n",
      "INFO:MaxText.pyconfig:Config param topk_routing_group: -1\n",
      "INFO:MaxText.pyconfig:Config param train_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param train_fraction: 1.0\n",
      "INFO:MaxText.pyconfig:Config param train_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param train_split: train\n",
      "INFO:MaxText.pyconfig:Config param trainable_position_size: -1\n",
      "INFO:MaxText.pyconfig:Config param trainer_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param upload_all_profiler_results: False\n",
      "INFO:MaxText.pyconfig:Config param use_batch_split_schedule: False\n",
      "INFO:MaxText.pyconfig:Config param use_chat_template: False\n",
      "INFO:MaxText.pyconfig:Config param use_chunked_prefill: False\n",
      "INFO:MaxText.pyconfig:Config param use_custom_sort_vjp: True\n",
      "INFO:MaxText.pyconfig:Config param use_dpo: False\n",
      "INFO:MaxText.pyconfig:Config param use_grpo: True\n",
      "INFO:MaxText.pyconfig:Config param use_iota_embed: False\n",
      "INFO:MaxText.pyconfig:Config param use_max_logit_estimate: -1\n",
      "INFO:MaxText.pyconfig:Config param use_multimodal: False\n",
      "INFO:MaxText.pyconfig:Config param use_pathways: True\n",
      "INFO:MaxText.pyconfig:Config param use_post_attn_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_post_ffw_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm_in_gdn: True\n",
      "INFO:MaxText.pyconfig:Config param use_qwix_quantization: False\n",
      "INFO:MaxText.pyconfig:Config param use_ragged_attention: False\n",
      "INFO:MaxText.pyconfig:Config param use_random_routing: False\n",
      "INFO:MaxText.pyconfig:Config param use_replicator_service: False\n",
      "INFO:MaxText.pyconfig:Config param use_ring_of_experts: False\n",
      "INFO:MaxText.pyconfig:Config param use_sft: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_gmm: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_splash: False\n",
      "INFO:MaxText.pyconfig:Config param use_truncation: True\n",
      "INFO:MaxText.pyconfig:Config param use_untrainable_positional_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param use_vertex_tensorboard: False\n",
      "INFO:MaxText.pyconfig:Config param using_pipeline_parallelism: False\n",
      "INFO:MaxText.pyconfig:Config param v_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param value_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_project: \n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_region: \n",
      "INFO:MaxText.pyconfig:Config param vision_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param vocab_size: 152064\n",
      "INFO:MaxText.pyconfig:Config param warmup_steps_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param weight_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param weight_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_mlp_dim: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information: Jax Version: 0.7.2\n",
      "System Information: Jaxlib Version: 0.7.2\n",
      "System Information: Jax Backend: cpu\n",
      "Num_devices: 1, shape (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "Lazy loading DISABLED. Loading full HuggingFace model: Qwen/Qwen2.5-14B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9482337b36f4de498522f618fe39420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace model loaded and converted to NumPy.\n",
      "[After full HF model load] RAM Usage: 86.62/1417.33 GB (6.1%)\n",
      "Creating checkpoint manager with ocdbt=True and zarr3=True\n",
      "Checkpoint manager created!\n",
      "Initializing MaxText abstract model...\n",
      "MaxText abstract model and state initialized.\n",
      "Parameter mappings and hooks obtained.\n",
      "Starting weight transformation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming weights: 100%|██████████| 15/15 [01:20<00:00,  5.36s/param, RAM: 136.1/1417.3GB (9.6%)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight transformation preparation complete.\n",
      "[Before creating full JAX tree] RAM Usage: 89.01/1417.33 GB (6.3%)\n",
      "[Before saving] RAM Usage: 89.01/1417.33 GB (6.3%)\n",
      "Starting checkpoint save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:absl:[process=0][thread=MainThread][operation_id=1] _SignalingThread.join() waiting for signals ([]) blocking the main thread will slow down blocking save times. This is likely due to main thread calling result() on a CommitFuture.\n",
      "WARNING:absl:[process=0][thread=MainThread][operation_id=1] _SignalingThread.join() waiting for signals ([]) blocking the main thread will slow down blocking save times. This is likely due to main thread calling result() on a CommitFuture.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved a checkpoint at step 0\n",
      "[Program Ends] RAM Usage: 109.66/1417.33 GB (7.7%)\n",
      "Conversion complete. Checkpoint saved to /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_v2/\n"
     ]
    }
   ],
   "source": [
    "main(args, test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db000bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/jimmy_workspace/maxtext\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jimmytsai_google_com/workspace/maxtext\n",
    "import MaxText\n",
    "from MaxText.utils.ckpt_conversion.to_huggingface import main\n",
    "MODEL_NAME='qwen2.5-14b'\n",
    "import dotenv\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "dotenv.load_dotenv(override=True)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "MAXTEXT_REPO_ROOT = os.path.dirname(MaxText.__file__)\n",
    "CKPT_PATH=\"gs://jimmytsai-dev/maxtext_sft/qwen2.5-14b/2026-01-05-02-43-bs16-data-ep2s1-gs1-lr1e-5-tp4-cff-0.2-total-lr-step-54/checkpoints/54/model_params\"\n",
    "args = [\n",
    "    \"\",\n",
    "    f\"{MAXTEXT_REPO_ROOT}/configs/base.yml\",\n",
    "    f\"model_name={MODEL_NAME}\",\n",
    "    f\"hf_access_token={HF_TOKEN}\",\n",
    "    f\"load_parameters_path={CKPT_PATH}\",\n",
    "    f'base_output_directory=\"/mnt/disks/jimmy_workspace/{MODEL_NAME}_checkpoint_hf/\"',\n",
    "    \"scan_layers=false\"\n",
    "]\n",
    "# Works exactly the same way\n",
    "test_args = SimpleNamespace(lazy_load_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax distributed system is already initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MaxText.pyconfig:Config param act_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param activations_in_float32: False\n",
      "INFO:MaxText.pyconfig:Config param adam_b1: 0.9\n",
      "INFO:MaxText.pyconfig:Config param adam_b2: 0.95\n",
      "INFO:MaxText.pyconfig:Config param adam_eps: 1e-08\n",
      "INFO:MaxText.pyconfig:Config param adam_eps_root: 0.0\n",
      "INFO:MaxText.pyconfig:Config param adam_weight_decay: 0.1\n",
      "INFO:MaxText.pyconfig:Config param add_bos: True\n",
      "INFO:MaxText.pyconfig:Config param add_eos: True\n",
      "INFO:MaxText.pyconfig:Config param allow_split_physical_axes: False\n",
      "INFO:MaxText.pyconfig:Config param ar_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param async_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param attention: autoselected\n",
      "INFO:MaxText.pyconfig:Config param attention_bias: True\n",
      "INFO:MaxText.pyconfig:Config param attention_sink: False\n",
      "INFO:MaxText.pyconfig:Config param attention_type: global\n",
      "INFO:MaxText.pyconfig:Config param attn_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param autoregressive_decode_assert: \n",
      "INFO:MaxText.pyconfig:Config param base_emb_dim: 5120\n",
      "INFO:MaxText.pyconfig:Config param base_mlp_dim: 13824\n",
      "INFO:MaxText.pyconfig:Config param base_moe_mlp_dim: 7168\n",
      "INFO:MaxText.pyconfig:Config param base_num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param base_num_kv_heads: 8\n",
      "INFO:MaxText.pyconfig:Config param base_num_query_heads: 40\n",
      "INFO:MaxText.pyconfig:Config param base_output_directory: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_hf/\n",
      "INFO:MaxText.pyconfig:Config param batch_size: 1\n",
      "INFO:MaxText.pyconfig:Config param beta_fast: 32\n",
      "INFO:MaxText.pyconfig:Config param beta_slow: 1\n",
      "INFO:MaxText.pyconfig:Config param bwd_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param capacity_factor: -1.0\n",
      "INFO:MaxText.pyconfig:Config param cast_logits_to_fp32: True\n",
      "INFO:MaxText.pyconfig:Config param chat_template_path: \n",
      "INFO:MaxText.pyconfig:Config param checkpoint_conversion_fn: None\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_hf/qwen2.5-14b_2026-01-05-09-37/checkpoints/\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_is_quantized: False\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_period: 10000\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_concurrent_gb: 96\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_target_data_file_size_bytes: 2147483648\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_ocdbt: True\n",
      "INFO:MaxText.pyconfig:Config param checkpoint_storage_use_zarr3: True\n",
      "INFO:MaxText.pyconfig:Config param chips_per_vm: 4\n",
      "INFO:MaxText.pyconfig:Config param chunk_attn_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param collect_stack_trace: False\n",
      "INFO:MaxText.pyconfig:Config param colocated_python_data_input: False\n",
      "INFO:MaxText.pyconfig:Config param compile_topology: \n",
      "INFO:MaxText.pyconfig:Config param compile_topology_num_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param compiled_trainstep_file: \n",
      "INFO:MaxText.pyconfig:Config param compute_axis_order: 0,1,2,3\n",
      "INFO:MaxText.pyconfig:Config param constant_bound_config: []\n",
      "INFO:MaxText.pyconfig:Config param context: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_load_balance: True\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_size: 1\n",
      "INFO:MaxText.pyconfig:Config param context_parallel_strategy: all_gather\n",
      "INFO:MaxText.pyconfig:Config param conv_stride_for_vit: 14\n",
      "INFO:MaxText.pyconfig:Config param cosine_learning_rate_final_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_bwd: -1\n",
      "INFO:MaxText.pyconfig:Config param cost_estimate_flops_fwd: -1\n",
      "INFO:MaxText.pyconfig:Config param custom_mesh: \n",
      "INFO:MaxText.pyconfig:Config param data_sharding: (('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive'),)\n",
      "INFO:MaxText.pyconfig:Config param data_shuffle_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param dataset_path: \n",
      "INFO:MaxText.pyconfig:Config param dataset_type: DatasetType.TFDS\n",
      "INFO:MaxText.pyconfig:Config param dcn_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_data_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param dcn_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_parallelism: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param dcn_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param dcn_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param debug: {'rl': False}\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_nucleus_p: -1\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_strategy: SamplingStrategy.GREEDY\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_temperature: 1.0\n",
      "INFO:MaxText.pyconfig:Config param decode_sampling_top_k: 0\n",
      "INFO:MaxText.pyconfig:Config param decoder_block: DecoderBlockType.QWEN2\n",
      "INFO:MaxText.pyconfig:Config param decoder_layer_input: RematLocation.DEVICE\n",
      "INFO:MaxText.pyconfig:Config param deepstack_visual_indexes_for_vit: []\n",
      "INFO:MaxText.pyconfig:Config param dpo_beta: 0.1\n",
      "INFO:MaxText.pyconfig:Config param dpo_label_smoothing: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dq_reduction_steps: 0\n",
      "INFO:MaxText.pyconfig:Config param dropout_rate: 0.0\n",
      "INFO:MaxText.pyconfig:Config param dtype: bfloat16\n",
      "INFO:MaxText.pyconfig:Config param dtype_mm: float32\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_delete_local_after: True\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_gcs_dir: \n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_dir: /tmp/xla_dump/\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_local_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_module_name: jit_train_step\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_upload_all: False\n",
      "INFO:MaxText.pyconfig:Config param dump_hlo_xla_flags: \n",
      "INFO:MaxText.pyconfig:Config param dump_step: -1\n",
      "INFO:MaxText.pyconfig:Config param emb_dim: 5120\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpoint_cloud_logger: False\n",
      "INFO:MaxText.pyconfig:Config param enable_checkpointing: True\n",
      "INFO:MaxText.pyconfig:Config param enable_data_shuffling: True\n",
      "INFO:MaxText.pyconfig:Config param enable_dropout: True\n",
      "INFO:MaxText.pyconfig:Config param enable_emergency_checkpoint: False\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_goodput_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_gcp_step_deviation_metrics: True\n",
      "INFO:MaxText.pyconfig:Config param enable_goodput_recording: False\n",
      "INFO:MaxText.pyconfig:Config param enable_jax_profiler: False\n",
      "INFO:MaxText.pyconfig:Config param enable_llm_inference_pool: False\n",
      "INFO:MaxText.pyconfig:Config param enable_model_warmup: False\n",
      "INFO:MaxText.pyconfig:Config param enable_multi_tier_checkpointing: False\n",
      "INFO:MaxText.pyconfig:Config param enable_nnx: False\n",
      "INFO:MaxText.pyconfig:Config param enable_orbax_v1: False\n",
      "INFO:MaxText.pyconfig:Config param enable_padding_causal_mask: True\n",
      "INFO:MaxText.pyconfig:Config param enable_pathways_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param enable_prefix_caching: False\n",
      "INFO:MaxText.pyconfig:Config param enable_rampup_batch_size: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_controller: False\n",
      "INFO:MaxText.pyconfig:Config param enable_single_replica_ckpt_restoring: False\n",
      "INFO:MaxText.pyconfig:Config param enable_tensorboard: True\n",
      "INFO:MaxText.pyconfig:Config param enable_tunix_perf_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param eval_corr_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param eval_dataset_name: c4/en:3.0.1\n",
      "INFO:MaxText.pyconfig:Config param eval_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param eval_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param eval_make_lst: False\n",
      "INFO:MaxText.pyconfig:Config param eval_per_device_batch_size: 12.0\n",
      "INFO:MaxText.pyconfig:Config param eval_sampling_strategy: greedy\n",
      "INFO:MaxText.pyconfig:Config param eval_split: validation\n",
      "INFO:MaxText.pyconfig:Config param eval_steps: -1\n",
      "INFO:MaxText.pyconfig:Config param expansion_factor_real_data: -1.0\n",
      "INFO:MaxText.pyconfig:Config param expert_shard_attention_option: fsdp\n",
      "INFO:MaxText.pyconfig:Config param final_logits_soft_cap: None\n",
      "INFO:MaxText.pyconfig:Config param first_num_dense_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param float32_logits: False\n",
      "INFO:MaxText.pyconfig:Config param float32_qk_product: False\n",
      "INFO:MaxText.pyconfig:Config param float32_weight_sum: True\n",
      "INFO:MaxText.pyconfig:Config param force_unroll: False\n",
      "INFO:MaxText.pyconfig:Config param freeze_vision_encoder_params: True\n",
      "INFO:MaxText.pyconfig:Config param fsdp_shard_on_exp: False\n",
      "INFO:MaxText.pyconfig:Config param fused_mlp: False\n",
      "INFO:MaxText.pyconfig:Config param fused_qkv: False\n",
      "INFO:MaxText.pyconfig:Config param gcs_metrics: False\n",
      "INFO:MaxText.pyconfig:Config param gdn_chunk_size: 64\n",
      "INFO:MaxText.pyconfig:Config param gdn_conv_kernel_dim: 4\n",
      "INFO:MaxText.pyconfig:Config param gdn_key_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_key_heads: 16\n",
      "INFO:MaxText.pyconfig:Config param gdn_num_value_heads: 32\n",
      "INFO:MaxText.pyconfig:Config param gdn_value_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_eval: False\n",
      "INFO:MaxText.pyconfig:Config param generate_padding_batch_train: False\n",
      "INFO:MaxText.pyconfig:Config param generate_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param generation_configs: {}\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_eval_on: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_eval: 192\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_increment: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_load_start: None\n",
      "INFO:MaxText.pyconfig:Config param global_batch_size_to_train_on: 192\n",
      "INFO:MaxText.pyconfig:Config param global_parameter_scale: 1\n",
      "INFO:MaxText.pyconfig:Config param global_rampup_samples: 500\n",
      "INFO:MaxText.pyconfig:Config param goodput_upload_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param grad_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param gradient_accumulation_steps: 1\n",
      "INFO:MaxText.pyconfig:Config param gradient_clipping_threshold: 1.0\n",
      "INFO:MaxText.pyconfig:Config param grain_data_source_max_workers: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_eval_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_file_type: arrayrecord\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_num_threads_eval: 16\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_per_worker_buffer_size_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_prefetch_buffer_size_eval: 500\n",
      "INFO:MaxText.pyconfig:Config param grain_train_files: \n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count: 1\n",
      "INFO:MaxText.pyconfig:Config param grain_worker_count_eval: 1\n",
      "INFO:MaxText.pyconfig:Config param grpo_beta: 0.08\n",
      "INFO:MaxText.pyconfig:Config param grpo_epsilon: 0.2\n",
      "INFO:MaxText.pyconfig:Config param hardware: tpu\n",
      "INFO:MaxText.pyconfig:Config param hbm_utilization_vllm: 0.72\n",
      "INFO:MaxText.pyconfig:Config param head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param heartbeat_reporting_interval_in_seconds: 5\n",
      "INFO:MaxText.pyconfig:Config param hf_data_dir: \n",
      "INFO:MaxText.pyconfig:Config param hf_eval_files: None\n",
      "INFO:MaxText.pyconfig:Config param hf_eval_split: \n",
      "INFO:MaxText.pyconfig:Config param hf_path: \n",
      "INFO:MaxText.pyconfig:Config param hf_train_files: None\n",
      "INFO:MaxText.pyconfig:Config param hidden_size_for_vit: 1408\n",
      "INFO:MaxText.pyconfig:Config param hide_profiler_step_metric: False\n",
      "INFO:MaxText.pyconfig:Config param ici_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_autoregressive_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_context_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_data_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_expert_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_parallelism: -1\n",
      "INFO:MaxText.pyconfig:Config param ici_fsdp_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_parallelism: [1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "INFO:MaxText.pyconfig:Config param ici_pipeline_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_sequence_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param ici_tensor_transpose_parallelism: 1\n",
      "INFO:MaxText.pyconfig:Config param image_path: \n",
      "INFO:MaxText.pyconfig:Config param image_placeholder: <|image|>\n",
      "INFO:MaxText.pyconfig:Config param image_size_for_vit: 896\n",
      "INFO:MaxText.pyconfig:Config param inference_benchmark_test: False\n",
      "INFO:MaxText.pyconfig:Config param inference_metadata_file: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_log_file_path: \n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_loop_iters: 10\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_num_samples: [1, 2, 3, 4, 5]\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_prefill_lengths: 64,128,256,512,1024\n",
      "INFO:MaxText.pyconfig:Config param inference_microbenchmark_stages: prefill,generate\n",
      "INFO:MaxText.pyconfig:Config param inference_server: MaxtextInterleavedServer\n",
      "INFO:MaxText.pyconfig:Config param inhomogeneous_layer_cycle_interval: 1\n",
      "INFO:MaxText.pyconfig:Config param init_weights_seed: 0\n",
      "INFO:MaxText.pyconfig:Config param input_data_sharding_logical_axes: ['activation_embed_and_logits_batch', 'activation_norm_length']\n",
      "INFO:MaxText.pyconfig:Config param interleave_moe_layer_step: 1\n",
      "INFO:MaxText.pyconfig:Config param intermediate_size_for_vit: 5632\n",
      "INFO:MaxText.pyconfig:Config param jax_cache_dir: ~/jax_cache\n",
      "INFO:MaxText.pyconfig:Config param jax_debug_log_modules: \n",
      "INFO:MaxText.pyconfig:Config param jax_distributed_initialization_timeout: 300\n",
      "INFO:MaxText.pyconfig:Config param jax_profiler_port: 9999\n",
      "INFO:MaxText.pyconfig:Config param key_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param kv_cache_buffer: 256\n",
      "INFO:MaxText.pyconfig:Config param kv_lora_rank: 512\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_axis: KvQuantAxis.HEADS_AND_DKV\n",
      "INFO:MaxText.pyconfig:Config param kv_quant_dtype: int8\n",
      "INFO:MaxText.pyconfig:Config param learning_rate: 3e-05\n",
      "INFO:MaxText.pyconfig:Config param learning_rate_schedule_steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param load_balance_loss_weight: 0.01\n",
      "INFO:MaxText.pyconfig:Config param load_from_prefill_dir: False\n",
      "INFO:MaxText.pyconfig:Config param load_full_state_path: \n",
      "INFO:MaxText.pyconfig:Config param load_parameters_path: gs://jimmytsai-dev/maxtext_sft/qwen2.5-14b/2026-01-05-02-43-bs16-data-ep2s1-gs1-lr1e-5-tp4-cff-0.2-total-lr-step-54/checkpoints/54/model_params\n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_directory: \n",
      "INFO:MaxText.pyconfig:Config param local_checkpoint_period: 0\n",
      "INFO:MaxText.pyconfig:Config param local_rope_max_timescale: -1\n",
      "INFO:MaxText.pyconfig:Config param log_config: True\n",
      "INFO:MaxText.pyconfig:Config param log_period: 100\n",
      "INFO:MaxText.pyconfig:Config param logical_axis_rules: (('activation_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_embed_and_logits_batch', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_embed_and_logits_batch_sequence', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('activation_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence', 'autoregressive')), ('activation_kv_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_length', ('sequence', 'context', 'expert')), ('activation_length', ('context', 'expert')), ('activation_length_no_exp', ('sequence', 'context')), ('activation_length_no_exp', ('context',)), ('activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_q_length', ('context', 'expert')), ('activation_q_length_no_exp', ('context',)), ('prefill_activation_length', ('sequence', 'context')), ('prefill_activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_kv_length', ()), ('activation_embed', ('tensor', 'tensor_transpose')), ('activation_mlp', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_kv', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_prefill_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_kv_head_dim', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose')), ('activation_vocab', 'tensor_sequence'), ('activation_vocab', ('sequence', 'context')), ('activation_stage', 'stage'), ('activation_exp', ('expert',)), ('decode_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('decode_length', ('sequence',)), ('mlp', ('fsdp_transpose', 'tensor', 'tensor_sequence', 'autoregressive')), ('mlp_no_fsdp', ('tensor', 'tensor_sequence', 'autoregressive')), ('vocab', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('q_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('kv_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'context', 'expert')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'context')), ('embed_tensor_transpose', ('tensor_transpose',)), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'expert')), ('q_lora_up_proj', ()), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'expert')), ('kv_lora_up_proj', ()), ('norm', ('tensor', 'tensor_transpose')), ('layers', 'stage'), ('kv', ()), ('kv_head_dim', ()), ('cache_batch_prefill', ()), ('cache_batch', ()), ('cache_heads_none', ()), ('cache_heads', ('autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence')), ('cache_heads', ('autoregressive', 'tensor', 'tensor_sequence')), ('cache_kv', ()), ('cache_sequence', ()), ('exp', 'expert'), ('paged_kv_heads', ('tensor',)), ('num_pages', ()), ('tokens_per_page', ()), ('paged_kv_head_dim_size', ()), ('dense_layers', ()), ('moe_layers', ()))\n",
      "INFO:MaxText.pyconfig:Config param logits_dot_in_fp32: False\n",
      "INFO:MaxText.pyconfig:Config param logits_via_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param lora_input_adapters_path: \n",
      "INFO:MaxText.pyconfig:Config param loss_algo: grpo\n",
      "INFO:MaxText.pyconfig:Config param matmul_precision: MatmulPrecision.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param max_checkify: False\n",
      "INFO:MaxText.pyconfig:Config param max_corpus_chars: 10000000\n",
      "INFO:MaxText.pyconfig:Config param max_num_checkpoints_to_keep: None\n",
      "INFO:MaxText.pyconfig:Config param max_num_images_per_example: -1\n",
      "INFO:MaxText.pyconfig:Config param max_position_embeddings: 163840\n",
      "INFO:MaxText.pyconfig:Config param max_prefill_predict_length: 64\n",
      "INFO:MaxText.pyconfig:Config param max_segments_per_seq: 32\n",
      "INFO:MaxText.pyconfig:Config param max_target_length: 2048\n",
      "INFO:MaxText.pyconfig:Config param megablox: True\n",
      "INFO:MaxText.pyconfig:Config param mesh_axes: ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive']\n",
      "INFO:MaxText.pyconfig:Config param metrics_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_hf/qwen2.5-14b_2026-01-05-09-37/metrics/\n",
      "INFO:MaxText.pyconfig:Config param metrics_file: \n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size: -1\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_eval_on: 192\n",
      "INFO:MaxText.pyconfig:Config param micro_batch_size_to_train_on: 192\n",
      "INFO:MaxText.pyconfig:Config param mla_naive_kvcache: True\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations: ['silu', 'linear']\n",
      "INFO:MaxText.pyconfig:Config param mlp_activations_limit: -1.0\n",
      "INFO:MaxText.pyconfig:Config param mlp_bias: False\n",
      "INFO:MaxText.pyconfig:Config param mlp_dim: 13824\n",
      "INFO:MaxText.pyconfig:Config param mlpwi: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_0: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwi_1: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param mlpwo: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param moba: False\n",
      "INFO:MaxText.pyconfig:Config param moba_chunk_size: 1024\n",
      "INFO:MaxText.pyconfig:Config param moba_topk: 8\n",
      "INFO:MaxText.pyconfig:Config param model_call_mode: \n",
      "INFO:MaxText.pyconfig:Config param model_fsdp_ag_once: False\n",
      "INFO:MaxText.pyconfig:Config param model_name: qwen2.5-14b\n",
      "INFO:MaxText.pyconfig:Config param moe_fsdp_use_two_stage_all_gather: False\n",
      "INFO:MaxText.pyconfig:Config param moe_mlp_dim: 7168\n",
      "INFO:MaxText.pyconfig:Config param monitor_goodput: False\n",
      "INFO:MaxText.pyconfig:Config param monitor_step_time_deviation: True\n",
      "INFO:MaxText.pyconfig:Config param mscale: 1.0\n",
      "INFO:MaxText.pyconfig:Config param mtc_data_parallelism: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_eval_target_module: 0\n",
      "INFO:MaxText.pyconfig:Config param mtp_loss_scaling_factor: 0.1\n",
      "INFO:MaxText.pyconfig:Config param mtp_num_layers: 0\n",
      "INFO:MaxText.pyconfig:Config param mu_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param multi_sampling: False\n",
      "INFO:MaxText.pyconfig:Config param multi_tier_checkpointing_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param n_routing_groups: -1\n",
      "INFO:MaxText.pyconfig:Config param nope_layer_interval: -1\n",
      "INFO:MaxText.pyconfig:Config param norm_topk_prob: False\n",
      "INFO:MaxText.pyconfig:Config param normalization_layer_epsilon: 1e-06\n",
      "INFO:MaxText.pyconfig:Config param normalize_embedding_logits: False\n",
      "INFO:MaxText.pyconfig:Config param num_attention_heads_for_vit: 16\n",
      "INFO:MaxText.pyconfig:Config param num_batches: 4\n",
      "INFO:MaxText.pyconfig:Config param num_channels_for_vit: 3\n",
      "INFO:MaxText.pyconfig:Config param num_decoder_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param num_epoch: 1\n",
      "INFO:MaxText.pyconfig:Config param num_eval_passes: 1\n",
      "INFO:MaxText.pyconfig:Config param num_experts: 1\n",
      "INFO:MaxText.pyconfig:Config param num_experts_per_tok: 1\n",
      "INFO:MaxText.pyconfig:Config param num_generations: 2\n",
      "INFO:MaxText.pyconfig:Config param num_hidden_layers_for_vit: 34\n",
      "INFO:MaxText.pyconfig:Config param num_iterations: 1\n",
      "INFO:MaxText.pyconfig:Config param num_kv_heads: 8\n",
      "INFO:MaxText.pyconfig:Config param num_layers_per_pipeline_stage: 1\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_microbatches: -1\n",
      "INFO:MaxText.pyconfig:Config param num_pipeline_repeats: -1\n",
      "INFO:MaxText.pyconfig:Config param num_position_embeddings_for_vit: 1024\n",
      "INFO:MaxText.pyconfig:Config param num_query_heads: 40\n",
      "INFO:MaxText.pyconfig:Config param num_samplers_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_slices: 1\n",
      "INFO:MaxText.pyconfig:Config param num_test_batches: 5\n",
      "INFO:MaxText.pyconfig:Config param num_trainer_slices: -1\n",
      "INFO:MaxText.pyconfig:Config param num_vocab_tiling: 1\n",
      "INFO:MaxText.pyconfig:Config param opt_type: OptimizerType.ADAMW\n",
      "INFO:MaxText.pyconfig:Config param optimize_mesh_for_tpu_v6e: False\n",
      "INFO:MaxText.pyconfig:Config param optimizer_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param original_max_position_embeddings: 4096\n",
      "INFO:MaxText.pyconfig:Config param out_hidden_size_for_vit: 512\n",
      "INFO:MaxText.pyconfig:Config param out_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param override_model_config: False\n",
      "INFO:MaxText.pyconfig:Config param packing: True\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_head_dim_alignment: 128\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_max_pages_per_group: -1\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_num_pages: 64\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_pages_per_compute_block: 4\n",
      "INFO:MaxText.pyconfig:Config param pagedattn_tokens_per_page: 32\n",
      "INFO:MaxText.pyconfig:Config param param_scan_axis: 1\n",
      "INFO:MaxText.pyconfig:Config param parameter_memory_host_offload: False\n",
      "INFO:MaxText.pyconfig:Config param partial_rotary_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param patch_size_for_vit: 14\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_answer: -1.0\n",
      "INFO:MaxText.pyconfig:Config param penalty_incorrect_format: -0.5\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size: 12.0\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_increment: 2.0\n",
      "INFO:MaxText.pyconfig:Config param per_device_batch_size_start: 4.0\n",
      "INFO:MaxText.pyconfig:Config param pipeline_delay_activation_forwarding: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_fsdp_ag_once: False\n",
      "INFO:MaxText.pyconfig:Config param pipeline_parallel_layers: 48\n",
      "INFO:MaxText.pyconfig:Config param pixel_shuffle_ratio_for_vit: 0.5\n",
      "INFO:MaxText.pyconfig:Config param posemb_type_for_vit: learn\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_axis_order: 1,2,0,3\n",
      "INFO:MaxText.pyconfig:Config param prefill_cache_dir: \n",
      "INFO:MaxText.pyconfig:Config param prefill_chunk_size: 256\n",
      "INFO:MaxText.pyconfig:Config param prefill_slice: v5e-16\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_dram_byte: 100000000000\n",
      "INFO:MaxText.pyconfig:Config param prefix_caching_hbm_byte: 10000000000\n",
      "INFO:MaxText.pyconfig:Config param profile_cleanly: True\n",
      "INFO:MaxText.pyconfig:Config param profile_periodically_period: -1\n",
      "INFO:MaxText.pyconfig:Config param profiler: ProfilerType.NONE\n",
      "INFO:MaxText.pyconfig:Config param profiler_steps: 5\n",
      "INFO:MaxText.pyconfig:Config param projector_dropout_for_vit: 0.0\n",
      "INFO:MaxText.pyconfig:Config param projector_input_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param projector_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param prometheus_port: 0\n",
      "INFO:MaxText.pyconfig:Config param prompt: I love to\n",
      "INFO:MaxText.pyconfig:Config param q_lora_rank: 0\n",
      "INFO:MaxText.pyconfig:Config param qk_nope_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param qk_rope_head_dim: 64\n",
      "INFO:MaxText.pyconfig:Config param qkv_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param quant_cfg_path: \n",
      "INFO:MaxText.pyconfig:Config param quantization: QuantizationType.NONE\n",
      "INFO:MaxText.pyconfig:Config param quantization_local_shard_count: 16\n",
      "INFO:MaxText.pyconfig:Config param quantize_kvcache: False\n",
      "INFO:MaxText.pyconfig:Config param query_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param ragged_block_size: 256\n",
      "INFO:MaxText.pyconfig:Config param rampup_end_step: 0\n",
      "INFO:MaxText.pyconfig:Config param rampup_samples_per_increment_to_load: None\n",
      "INFO:MaxText.pyconfig:Config param reasoning_end_token: </reasoning>\n",
      "INFO:MaxText.pyconfig:Config param reasoning_start_token: <reasoning>\n",
      "INFO:MaxText.pyconfig:Config param record_internal_nn_metrics: 0\n",
      "INFO:MaxText.pyconfig:Config param remat_policy: full\n",
      "INFO:MaxText.pyconfig:Config param remat_policy_for_vit: minimal\n",
      "INFO:MaxText.pyconfig:Config param replicate_quant_scale: False\n",
      "INFO:MaxText.pyconfig:Config param replicator_backup_interval_minutes: 0\n",
      "INFO:MaxText.pyconfig:Config param report_heartbeat_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param report_performance_metric_for_gcp_monitoring: False\n",
      "INFO:MaxText.pyconfig:Config param reshape_q: False\n",
      "INFO:MaxText.pyconfig:Config param return_log_prob: False\n",
      "INFO:MaxText.pyconfig:Config param reuse_example_batch: 0\n",
      "INFO:MaxText.pyconfig:Config param reward_exact_format_match: 3.0\n",
      "INFO:MaxText.pyconfig:Config param reward_partial_format_match: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_high: 0.5\n",
      "INFO:MaxText.pyconfig:Config param reward_ratio_guess_to_answer_low: 0.25\n",
      "INFO:MaxText.pyconfig:Config param reward_white_space_format_match: 1.5\n",
      "INFO:MaxText.pyconfig:Config param rope_attention_scaling: False\n",
      "INFO:MaxText.pyconfig:Config param rope_factor: 40\n",
      "INFO:MaxText.pyconfig:Config param rope_interleave: True\n",
      "INFO:MaxText.pyconfig:Config param rope_linear_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param rope_max_timescale: 1000000\n",
      "INFO:MaxText.pyconfig:Config param rope_min_timescale: 1\n",
      "INFO:MaxText.pyconfig:Config param rope_theta_for_vit: 10000\n",
      "INFO:MaxText.pyconfig:Config param rope_truncate: True\n",
      "INFO:MaxText.pyconfig:Config param rope_type: RopeType.DEFAULT\n",
      "INFO:MaxText.pyconfig:Config param rope_use_scale: True\n",
      "INFO:MaxText.pyconfig:Config param routed_bias: False\n",
      "INFO:MaxText.pyconfig:Config param routed_scaling_factor: 1.0\n",
      "INFO:MaxText.pyconfig:Config param routed_score_func: \n",
      "INFO:MaxText.pyconfig:Config param run_name: qwen2.5-14b_2026-01-05-09-37\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dkv_compute: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_kv_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dkv: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_block_q_dq: 512\n",
      "INFO:MaxText.pyconfig:Config param sa_k_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_q_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sa_use_fused_bwd_kernel: False\n",
      "INFO:MaxText.pyconfig:Config param sa_v_layout: HEAD_DIM_MINOR\n",
      "INFO:MaxText.pyconfig:Config param sampler_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param save_checkpoint_on_completion: True\n",
      "INFO:MaxText.pyconfig:Config param save_config_to_gcs: False\n",
      "INFO:MaxText.pyconfig:Config param save_quantized_params_path: \n",
      "INFO:MaxText.pyconfig:Config param scan_layers: False\n",
      "INFO:MaxText.pyconfig:Config param scan_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param scan_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_layers_per_stage: False\n",
      "INFO:MaxText.pyconfig:Config param set_remat_policy_on_pipeline_iterations: True\n",
      "INFO:MaxText.pyconfig:Config param sft_train_on_completion_only: False\n",
      "INFO:MaxText.pyconfig:Config param shard_mode: ShardMode.AUTO\n",
      "INFO:MaxText.pyconfig:Config param shard_optimizer_over_data: False\n",
      "INFO:MaxText.pyconfig:Config param sharding_strategy: None\n",
      "INFO:MaxText.pyconfig:Config param sharding_tolerance: 0.02\n",
      "INFO:MaxText.pyconfig:Config param shardy: True\n",
      "INFO:MaxText.pyconfig:Config param shared_experts: 1\n",
      "INFO:MaxText.pyconfig:Config param skip_first_n_steps_for_profiler: 1\n",
      "INFO:MaxText.pyconfig:Config param skip_jax_distributed_system: False\n",
      "INFO:MaxText.pyconfig:Config param sliding_window_size: 0\n",
      "INFO:MaxText.pyconfig:Config param solution_end_token: </answer>\n",
      "INFO:MaxText.pyconfig:Config param solution_start_token: <answer>\n",
      "INFO:MaxText.pyconfig:Config param source_checkpoint_layout: orbax\n",
      "INFO:MaxText.pyconfig:Config param sparse_matmul: True\n",
      "INFO:MaxText.pyconfig:Config param spatial_merge_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param stack_prefill_result_cache: False\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_interval_seconds: 600\n",
      "INFO:MaxText.pyconfig:Config param stack_trace_to_cloud: False\n",
      "INFO:MaxText.pyconfig:Config param step_deviation_interval_seconds: 30\n",
      "INFO:MaxText.pyconfig:Config param steps: 150001\n",
      "INFO:MaxText.pyconfig:Config param subslice_shape: \n",
      "INFO:MaxText.pyconfig:Config param swap_space_vllm_gb: 2\n",
      "INFO:MaxText.pyconfig:Config param target_eval_loss: 0.0\n",
      "INFO:MaxText.pyconfig:Config param temperature_tuning: False\n",
      "INFO:MaxText.pyconfig:Config param temporal_patch_size_for_vit: 2\n",
      "INFO:MaxText.pyconfig:Config param tensorboard_dir: /mnt/disks/jimmy_workspace/qwen2.5-14b_checkpoint_hf/qwen2.5-14b_2026-01-05-09-37/tensorboard/\n",
      "INFO:MaxText.pyconfig:Config param tensors_on_device: None\n",
      "INFO:MaxText.pyconfig:Config param tensors_to_offload: None\n",
      "INFO:MaxText.pyconfig:Config param tile_size_for_vit: 336\n",
      "INFO:MaxText.pyconfig:Config param tokenize_eval_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenize_train_data: True\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_path: src/MaxText/assets/tokenizer.llama2\n",
      "INFO:MaxText.pyconfig:Config param tokenizer_type: TokenizerType.HUGGINGFACE\n",
      "INFO:MaxText.pyconfig:Config param topk_routing_group: -1\n",
      "INFO:MaxText.pyconfig:Config param train_data_columns: ['text']\n",
      "INFO:MaxText.pyconfig:Config param train_fraction: 1.0\n",
      "INFO:MaxText.pyconfig:Config param train_image_column: image\n",
      "INFO:MaxText.pyconfig:Config param train_split: train\n",
      "INFO:MaxText.pyconfig:Config param trainable_position_size: -1\n",
      "INFO:MaxText.pyconfig:Config param trainer_devices_fraction: 0.5\n",
      "INFO:MaxText.pyconfig:Config param upload_all_profiler_results: False\n",
      "INFO:MaxText.pyconfig:Config param use_batch_split_schedule: False\n",
      "INFO:MaxText.pyconfig:Config param use_chat_template: False\n",
      "INFO:MaxText.pyconfig:Config param use_chunked_prefill: False\n",
      "INFO:MaxText.pyconfig:Config param use_custom_sort_vjp: True\n",
      "INFO:MaxText.pyconfig:Config param use_dpo: False\n",
      "INFO:MaxText.pyconfig:Config param use_grpo: True\n",
      "INFO:MaxText.pyconfig:Config param use_iota_embed: False\n",
      "INFO:MaxText.pyconfig:Config param use_max_logit_estimate: -1\n",
      "INFO:MaxText.pyconfig:Config param use_multimodal: False\n",
      "INFO:MaxText.pyconfig:Config param use_pathways: True\n",
      "INFO:MaxText.pyconfig:Config param use_post_attn_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_post_ffw_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm: False\n",
      "INFO:MaxText.pyconfig:Config param use_qk_norm_in_gdn: True\n",
      "INFO:MaxText.pyconfig:Config param use_qwix_quantization: False\n",
      "INFO:MaxText.pyconfig:Config param use_ragged_attention: False\n",
      "INFO:MaxText.pyconfig:Config param use_random_routing: False\n",
      "INFO:MaxText.pyconfig:Config param use_replicator_service: False\n",
      "INFO:MaxText.pyconfig:Config param use_ring_of_experts: False\n",
      "INFO:MaxText.pyconfig:Config param use_sft: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_gmm: False\n",
      "INFO:MaxText.pyconfig:Config param use_tokamax_splash: False\n",
      "INFO:MaxText.pyconfig:Config param use_truncation: True\n",
      "INFO:MaxText.pyconfig:Config param use_untrainable_positional_embedding: False\n",
      "INFO:MaxText.pyconfig:Config param use_vertex_tensorboard: False\n",
      "INFO:MaxText.pyconfig:Config param using_pipeline_parallelism: False\n",
      "INFO:MaxText.pyconfig:Config param v_head_dim: 128\n",
      "INFO:MaxText.pyconfig:Config param value_proj: RematLocation.REMAT\n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_project: \n",
      "INFO:MaxText.pyconfig:Config param vertex_tensorboard_region: \n",
      "INFO:MaxText.pyconfig:Config param vision_output_dim_for_vit: 4096\n",
      "INFO:MaxText.pyconfig:Config param vocab_size: 152064\n",
      "INFO:MaxText.pyconfig:Config param warmup_steps_fraction: 0.1\n",
      "INFO:MaxText.pyconfig:Config param weight_dtype: float32\n",
      "INFO:MaxText.pyconfig:Config param weight_quantization_calibration_method: absmax\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wi_tile_fwd_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_dlhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_drhs_mlp_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_batch_seq: 512\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_embed_dim: 1024\n",
      "INFO:MaxText.pyconfig:Config param wo_tile_fwd_mlp_dim: 1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Information: Jax Version: 0.7.2\n",
      "System Information: Jaxlib Version: 0.7.2\n",
      "System Information: Jax Backend: cpu\n",
      "\n",
      "Loading Orbax checkpoint...\n",
      "Num_devices: 16, shape (1, 1, 16, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "Loading decode params from gs://jimmytsai-dev/maxtext_sft/qwen2.5-14b/2026-01-05-02-43-bs16-data-ep2s1-gs1-lr1e-5-tp4-cff-0.2-total-lr-step-54/checkpoints/54/model_params\n",
      "restoring params from gs://jimmytsai-dev/maxtext_sft/qwen2.5-14b/2026-01-05-02-43-bs16-data-ep2s1-gs1-lr1e-5-tp4-cff-0.2-total-lr-step-54/checkpoints/54/model_params\n",
      "Creating checkpoint manager with ocdbt=True and zarr3=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memstats: After load_params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMemstats unavailable, error: 'NoneType' object is not subscriptable\n",
      "\n",
      "RAMstats: After load_params:\n",
      "\tUsing (GB) 35.05 / 1417.33 (2.472960%) -->  Available:1382.28\n",
      "Elapse: 3.07 min\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Leaf value for params-decoder-decoder_norm-scale is not an array. Type: <class 'jax._src.core.ShapeDtypeStruct'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/disks/jimmy_workspace/maxtext/src/MaxText/utils/ckpt_conversion/to_huggingface.py:236\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(argv)\u001b[39m\n\u001b[32m    234\u001b[39m   \u001b[38;5;66;03m# Check leaf value is an array\u001b[39;00m\n\u001b[32m    235\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(leaf_value, (jax.Array, np.ndarray)):\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLeaf value for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxtext_param_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not an array. Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(leaf_value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    237\u001b[39m   maxtext_state_dict[maxtext_param_key] = leaf_value\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# The param_map may contain tuples as keys, which represent N-to-1 mappings from maxtext to huggingface\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# Check maxtext_state_dict is a subset of flattened param_map\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# Skip extra keys from param_map\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Leaf value for params-decoder-decoder_norm-scale is not an array. Type: <class 'jax._src.core.ShapeDtypeStruct'>."
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maxtext_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
